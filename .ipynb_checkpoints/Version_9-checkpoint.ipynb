{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 9: Fine-tuning with Lower Lasso Alpha\n",
    "\n",
    "## Introduction: Changes & Purpose\n",
    "In Version 9, we implemented fine-tuning by reducing the Lasso regularization parameter (alpha).\n",
    "- **Change:** Lowered the Lasso alpha value to reduce the extent of coefficient shrinkage.\n",
    "- **Purpose:** This adjustment aimed to retain more informative features while still controlling for overfitting, thereby improving the model's generalization on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leonk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leonk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE (log scale): 0.08\n",
      "Test RMSE (log scale): 0.08\n",
      "R² Score: 0.9605\n",
      "Test RMSE (Original Scale): 564.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 01:17:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model from Version 9 saved and registered successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'CarPriceRidgeModel' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'CarPriceRidgeModel'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set MLflow experiment for Version 9\n",
    "mlflow.set_experiment(\"Car Price Prediction - Version 9\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # 1. Data Loading and Preprocessing\n",
    "    df = pd.read_csv(\"car_price_dataset.csv\")\n",
    "    \n",
    "    # Map categorical features to numerical values\n",
    "    brand_mapping = {\n",
    "        \"Audi\": 0, \"BMW\": 1, \"Mercedes\": 2, \"Volkswagen\": 3,\n",
    "        \"Toyota\": 4, \"Ford\": 5, \"Honda\": 6, \"Chevrolet\": 7,\n",
    "        \"Kia\": 8, \"Hyundai\": 9\n",
    "    }\n",
    "    fuel_mapping = {\n",
    "        \"Petrol\": 0, \"Diesel\": 1, \"Electric\": 2, \"Hybrid\": 3\n",
    "    }\n",
    "    transmission_mapping = {\n",
    "        \"Manual\": 0, \"Automatic\": 1, \"Semi-Automatic\": 2\n",
    "    }\n",
    "    \n",
    "    df[\"Brand\"] = df[\"Brand\"].map(brand_mapping)\n",
    "    df[\"Fuel_Type\"] = df[\"Fuel_Type\"].map(fuel_mapping)\n",
    "    df[\"Transmission\"] = df[\"Transmission\"].map(transmission_mapping)\n",
    "    \n",
    "    # Feature Engineering:\n",
    "    # Calculate car age and apply a square root transformation to Mileage\n",
    "    current_year = datetime.datetime.now().year\n",
    "    df[\"Car_Age\"] = current_year - df[\"Year\"]\n",
    "    df[\"Mileage_sqrt\"] = np.sqrt(df[\"Mileage\"])\n",
    "    \n",
    "    # Log-transform the target variable to reduce skewness\n",
    "    df[\"Log_Price\"] = np.log1p(df[\"Price\"])\n",
    "    \n",
    "    # Select features and target\n",
    "    features = [\"Brand\", \"Engine_Size\", \"Mileage_sqrt\", \"Car_Age\", \"Fuel_Type\", \"Transmission\", \"Doors\"]\n",
    "    X = df[features]\n",
    "    y = df[\"Log_Price\"]\n",
    "    \n",
    "    # Drop any rows with missing values in our selected columns\n",
    "    df = df.dropna(subset=features + [\"Log_Price\"])\n",
    "    \n",
    "    # 2. Data Splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 3. Model Training using a Pipeline with Polynomial Expansion and Lasso Regularization\n",
    "    # In Version 9, we fine-tune by lowering the Lasso alpha value\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=3, include_bias=False)),  # Use polynomial features to capture non-linearities\n",
    "        ('lasso', Lasso(alpha=0.01, max_iter=10000))  # Fine-tuned lower alpha for less aggressive shrinkage\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 4. Evaluation: Predictions & Metrics\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    train_rmse_log = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "    test_rmse_log = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"Train RMSE (log scale): {train_rmse_log:.2f}\")\n",
    "    print(f\"Test RMSE (log scale): {test_rmse_log:.2f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Optionally, convert predictions back to the original price scale for additional evaluation\n",
    "    y_test_pred_actual = np.expm1(y_test_pred)\n",
    "    y_test_actual = np.expm1(y_test)\n",
    "    test_rmse_actual = np.sqrt(mean_squared_error(y_test_actual, y_test_pred_actual))\n",
    "    print(f\"Test RMSE (Original Scale): {test_rmse_actual:.2f}\")\n",
    "    \n",
    "    # 5. MLflow Logging: Parameters, Metrics, and Artifacts\n",
    "    mlflow.log_param(\"model_type\", \"Lasso Regression with Polynomial Expansion\")\n",
    "    mlflow.log_param(\"lasso_alpha\", 0.01)\n",
    "    mlflow.log_param(\"poly_degree\", 3)\n",
    "    mlflow.log_metric(\"train_rmse_log\", train_rmse_log)\n",
    "    mlflow.log_metric(\"test_rmse_log\", test_rmse_log)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"test_rmse_original\", test_rmse_actual)\n",
    "    \n",
    "    # Save model parameters artifact (optional)\n",
    "    final_model_info = {\n",
    "        \"lasso_intercept\": float(pipeline.named_steps['lasso'].intercept_),\n",
    "        \"lasso_coefficients\": pipeline.named_steps['lasso'].coef_.tolist(),\n",
    "        \"scaler_mean\": pipeline.named_steps['scaler'].mean_.tolist(),\n",
    "        \"scaler_scale\": pipeline.named_steps['scaler'].scale_.tolist()\n",
    "    }\n",
    "    with open(\"final_model_v9.json\", \"w\") as f:\n",
    "        json.dump(final_model_info, f)\n",
    "    mlflow.log_artifact(\"final_model_v9.json\", artifact_path=\"model_artifacts\")\n",
    "    \n",
    "    # Log the entire model using MLflow's scikit-learn integration\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "    \n",
    "    # 6. Register the Model in the MLflow Model Registry\n",
    "    # Note: This registration creates a new model version under the name 'CarPriceRidgeModel'\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/model\"\n",
    "    registered_model_name = \"CarPriceRidgeModel\"\n",
    "    mlflow.register_model(model_uri, registered_model_name)\n",
    "    \n",
    "    print(\"Final model from Version 9 saved and registered successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Discussion for Version 9\n",
    "\n",
    "The final model in Version 9, which was fine-tuned by lowering the Lasso regularization parameter (alpha = 0.01), achieved the following performance metrics:\n",
    "\n",
    "- **Train RMSE (log scale):** 0.08  \n",
    "- **Test RMSE (log scale):** 0.08  \n",
    "- **R² Score:** 0.9605  \n",
    "- **Test RMSE (Original Scale):** 564.16\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "- **Low RMSE on Log Scale:**  \n",
    "  The extremely low RMSE values on the log-transformed scale (0.08 for both train and test sets) indicate that the model fits the transformed data very well.\n",
    "\n",
    "- **R² Score of 0.9605:**  \n",
    "  An R² score of 0.9605 suggests that approximately 96% of the variance in the log-transformed car prices is explained by the model. This is a strong indicator of model performance.\n",
    "\n",
    "- **Test RMSE on Original Scale:**  \n",
    "  The test RMSE of 564.16 on the original price scale implies that, on average, the predicted prices differ from the actual prices by about €564. This difference, when considered in the context of car prices, demonstrates that the model maintains a good balance between precision and generalization.\n",
    "\n",
    "### Model Registration\n",
    "\n",
    "After logging the run in MLflow, the model was automatically registered under the name **\"CarPriceRidgeModel\"**. Since this model already existed, a new version (Version 3) was created. This ensures that the most recent and best performing model is available for deployment in Phase 3.\n",
    "\n",
    "### Overall Conclusion\n",
    "\n",
    "The results indicate that the fine-tuning in Version 9 has led to a model that:\n",
    "- **Generalizes well** to new data, as evidenced by the similar training and test RMSE values.\n",
    "- **Explains a high percentage** of variance in the transformed target variable.\n",
    "- **Produces practical predictions** on the original scale, with an average error of around €564.\n",
    "\n",
    "This comprehensive performance analysis confirms that the model is well-prepared for the next phase, where it will be deployed in a Streamlit app for real-time predictions.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
